{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "import pandas as pd\n",
    "\n",
    "from covid_model_deaths.data import get_input_data, plot_crude_rates\n",
    "from covid_model_deaths.globals import COLUMNS\n",
    "from covid_model_deaths import runner\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'dev'\n",
    "DATA_VERSION = 'best'\n",
    "DATESTAMP_LABEL = '2020_04_24_Europe'\n",
    "\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/peak_locs_april20_.csv.csv'\n",
    "PEAK_DURATION_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/smooth_peak_duration.csv'\n",
    "R0_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_14/R0_dates.csv'\n",
    "LOCATION_SET_VERSION = 649\n",
    "\n",
    "\n",
    "# # read in cov input file (predicted date of R0 == 1) to see if we are using these for a given location\n",
    "# cov_df = pd.read_csv(R0_FILE)\n",
    "# r0_locs = cov_df['location_id'].unique().tolist()\n",
    "# del cov_df\n",
    "r0_locs = []\n",
    "\n",
    "# # less conservative peak ranges\n",
    "# peak_dur_df = pd.read_csv(PEAK_DURATION_FILE)\n",
    "# peak_dur_df = peak_dur_df.loc[peak_dur_df['Location'] != 'Colorado']\n",
    "# peak_dur_df['peak start date'] = pd.to_datetime(peak_dur_df['peak start date'])\n",
    "# peak_dur_df['peak end date'] = pd.to_datetime(peak_dur_df['peak end date'])\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "checkpoint = runner.Checkpoint(OUTPUT_DIR)\n",
    "\n",
    "print(f'Writing to {OUTPUT_DIR}')\n",
    "print(CODE_DIR)\n",
    "print(checkpoint)\n",
    "\n",
    "raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_euro_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_23_Europe_rerun/euro_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_22_Europe/euro_data.csv'\n",
    "\n",
    "\n",
    "def filter_data(data: pd.DataFrame, kind='full') -> pd.DataFrame:\n",
    "    # manually adjust Iceland spike (0 deaths to 5 deaths to 0 deaths in March...)\n",
    "    iceland = data['Country/Region'] == 'Iceland'\n",
    "    iceland_spike = iceland & (data['Date'] == pd.Timestamp('2020-03-15'))\n",
    "    if kind == 'full':\n",
    "        data.loc[iceland_spike, ['Deaths', 'Death rate']] = 0\n",
    "    elif kind == 'deaths':\n",
    "        data = data.loc[~iceland_spike]\n",
    "        min_iceland_date = data.loc[iceland, 'Date'].min()\n",
    "        data.loc[iceland, 'Days'] = (data.loc[iceland, 'Date'] - min_iceland_date).dt.days\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_locations(location_set_version_id):\n",
    "    # get locaton_ids\n",
    "    loc_df = get_location_metadata(location_set_id=111, \n",
    "                                   location_set_version_id=location_set_version_id)\n",
    "    \n",
    "    # Drop any locations in the US and keep only most detailed for modeling\n",
    "    most_detailed = loc_df['most_detailed'] == 1\n",
    "    non_us = ~loc_df['path_to_top_parent'].str.startswith('102,')\n",
    "    # Bad aggregates that made it in the hierarchy\n",
    "    good_ids = ~loc_df['location_id'].isin([53474, 53451, 53452]) \n",
    "    keep_columns = ['location_id', 'location_ascii_name', 'parent_id', 'level', 'most_detailed']\n",
    "    \n",
    "    euro_df = loc_df.loc[most_detailed & non_us & good_ids, keep_columns]\n",
    "    euro_df = euro_df.rename(columns={'location_ascii_name':'Location'})\n",
    "    \n",
    "    # Add parents\n",
    "    loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "    loc_df = loc_df.rename(columns={'location_id':'parent_id',\n",
    "                                    'location_ascii_name':'Country/Region'})\n",
    "    euro_df = euro_df.merge(loc_df)\n",
    "\n",
    "    euro_df = euro_df.loc[:, ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "    return euro_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = get_locations(LOCATION_SET_VERSION)\n",
    "input_full_df = filter_data(get_input_data('full_data', DATA_VERSION))\n",
    "input_death_df = filter_data(get_input_data('deaths', DATA_VERSION), kind='deaths')\n",
    "input_age_pop_df = get_input_data('age_pop', DATA_VERSION)\n",
    "input_age_death_df = get_input_data('age_death', DATA_VERSION)\n",
    "\n",
    "# Save pops for Bobby.\n",
    "pop_df = input_age_pop_df.merge(loc_df).reset_index(drop=True)\n",
    "pop_df[['location_id', 'Location', 'age_group', 'population']].to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "\n",
    "checkpoint.write('location', loc_df)\n",
    "checkpoint.write('full_data', input_full_df)\n",
    "checkpoint.write('deaths', input_death_df)\n",
    "checkpoint.write('age_pop', input_age_pop_df)\n",
    "checkpoint.write('age_death', input_age_death_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## prepare data for case-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "\n",
    "backcast_location_ids = runner.get_backcast_location_ids(full_df, most_detailed=False)\n",
    "cases_and_backcast_deaths_df = runner.make_cases_and_backcast_deaths(full_df, death_df, age_pop_df, age_death_df, backcast_location_ids, subnat=False)\n",
    "\n",
    "cases_and_backcast_deaths_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n",
    "checkpoint.write('cases_and_backcast_deaths', cases_and_backcast_deaths_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute death thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cases_and_backcast_deaths_df = checkpoint.load('cases_and_backcast_deaths')\n",
    "loc_df = checkpoint.load('location')\n",
    "threshold_dates = runner.impute_death_threshold(cases_and_backcast_deaths_df,\n",
    "                                                loc_df)\n",
    "threshold_dates.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "checkpoint.write('threshold_dates', threshold_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make last day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "\n",
    "date_mean_df = runner.make_date_mean_df(threshold_dates)\n",
    "last_day_df = runner.make_last_day_df(full_df,date_mean_df)\n",
    "last_day_df.to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "checkpoint.write('date_mean', date_mean_df)\n",
    "checkpoint.write('last_day', last_day_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store model data and covariate data, submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "date_mean_df = checkpoint.load('date_mean')\n",
    "last_day_df = checkpoint.load('last_day')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "dcr_df, dhr_df, li_df = runner.make_leading_indicator(\n",
    "    full_df.loc[full_df[COLUMNS.location_id].isin(loc_df[COLUMNS.location_id].to_list())]\n",
    ")\n",
    "dcr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_case_ratios.csv', index=False)\n",
    "dhr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_hosp_ratios.csv', index=False)\n",
    "li_df.to_csv(f'{OUTPUT_DIR}/leading_indicator.csv', index=False)\n",
    "li_df = li_df[[COLUMNS.location_id, COLUMNS.date, COLUMNS.ln_age_death_rate]]\n",
    "li_df = li_df.loc[~li_df[COLUMNS.ln_age_death_rate].isnull()]\n",
    "\n",
    "submodel_dict = runner.submit_models(full_df, death_df, age_pop_df, age_death_df, date_mean_df, li_df,\n",
    "                                     loc_df, r0_locs, PEAK_FILE, OUTPUT_DIR, DATA_VERSION, R0_FILE, CODE_DIR)\n",
    "\n",
    "checkpoint.write('submodel_dict', submodel_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "obs_df = full_df[full_df.location_id.isin(loc_df.location_id)]\n",
    "\n",
    "draw_dfs, past_draw_dfs, models_used, days, ensemble_draws_dfs = runner.compile_draws(loc_df,\n",
    "                                                                                      submodel_dict,\n",
    "                                                                                      obs_df,\n",
    "                                                                                      threshold_dates,\n",
    "                                                                                      age_pop_df)\n",
    "\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({'location': loc_df['Location'].unique().tolist(),\n",
    "                              'model_used': models_used})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/euro_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/models_used.csv', index=False)\n",
    "ensemble_plot_path = runner.make_and_save_draw_plots(OUTPUT_DIR, loc_df,\n",
    "                                                     ensemble_draws_dfs, days, models_used, age_pop_df)\n",
    "print(ensemble_plot_path)\n",
    "checkpoint.write('draw_data', draw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_df = runner.average_draws(raw_draw_path, yesterday_draw_path, before_yesterday_draw_path)\n",
    "avg_df.to_csv(average_draw_path, index=False)\n",
    "compare_average_plot_path = runner.make_and_save_compare_average_plots(OUTPUT_DIR,\n",
    "                                                                       raw_draw_path,\n",
    "                                                                       average_draw_path,\n",
    "                                                                       yesterday_draw_path,\n",
    "                                                                       before_yesterday_draw_path,\n",
    "                                                                       'Not United States of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_to_previous_plot_path = runner.make_and_save_compare_to_previous_plots(OUTPUT_DIR, \n",
    "                                                                               raw_draw_path, \n",
    "                                                                               yesterday_draw_path, \n",
    "                                                                               \"Not US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "viz_dir = runner.send_plots_to_diagnostics(DATESTAMP_LABEL,\n",
    "                                           f'{OUTPUT_DIR}/ensemble_plot.pdf',\n",
    "                                           compare_average_plot_path,\n",
    "                                           compare_to_previous_plot_path)\n",
    "print(viz_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

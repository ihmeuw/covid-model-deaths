{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "from covid_model_deaths import runner\n",
    "from covid_model_deaths.deaths_io import InputsContext, MEASURES, Checkpoint\n",
    "from covid_model_deaths.globals import COLUMNS\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DATE = \"2020_05_29\" # Date for all data used\n",
    "# Completed these \"2020-03-27\", \"2020-04-03\", \"2020-04-10\",\n",
    "# \"2020-04-17\" breaks, do the rest?\n",
    "# date_list = [\"2020-04-24\",\"2020-05-01\",\"2020-05-08\",\"2020-05-15\",\"2020-05-22\",\"2020-05-29\"]\n",
    "# date_list = [\"2020-03-27\", \"2020-04-03\", \"2020-04-10\", \"2020-04-17\"]\n",
    "date_list = [\"2020-03-31\",\"2020-04-03\", \"2020-04-10\"] #, \n",
    "date_list = [\"2020-04-24\",\"2020-05-01\",\"2020-05-08\",\"2020-05-15\",\"2020-05-22\",\"2020-05-29\"]\n",
    "# \"2020-03-27\" breaks ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-08 11:23:48.255 | DEBUG    | covid_model_deaths.deaths_io.checkpoint:_setup_checkpoint_dir:45 - Making checkpoint directory at /ihme/covid-19/deaths/validation/2020_05_29/2020_04_24/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /ihme/covid-19/deaths/validation/2020_05_29/2020_04_24\n",
      "/ihme/code/covid-19/user/ctroeger/covid-model-deaths/src/src/covid_model_deaths\n",
      "Checkpoint(/ihme/covid-19/deaths/validation/2020_05_29/2020_04_24/checkpoint)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-08 11:23:48.491 | DEBUG    | covid_model_deaths.deaths_io.inputs:load:40 - Loading full_data.csv from /ihme/covid-19/model-inputs/2020_05_29.01.\n",
      "2020-06-08 11:23:48.547 | DEBUG    | covid_model_deaths.deaths_io.inputs:load:40 - Loading deaths.csv from /ihme/covid-19/model-inputs/2020_05_29.01.\n",
      "2020-06-08 11:23:48.586 | DEBUG    | covid_model_deaths.deaths_io.inputs:load:40 - Loading age_pop.csv from /ihme/covid-19/model-inputs/2020_05_29.01.\n",
      "2020-06-08 11:23:48.594 | DEBUG    | covid_model_deaths.deaths_io.inputs:load:40 - Loading age_death.csv from /ihme/covid-19/model-inputs/2020_05_29.01.\n",
      "2020-06-08 11:24:03.173 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading full_data from in memory cache.\n",
      "2020-06-08 11:24:03.176 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading deaths from in memory cache.\n",
      "2020-06-08 11:24:03.177 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading age_pop from in memory cache.\n",
      "2020-06-08 11:24:03.178 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading age_death from in memory cache.\n",
      "100%|██████████| 324/324 [04:19<00:00,  1.25it/s]\n",
      "2020-06-08 11:28:23.699 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading cases_and_backcast_deaths from in memory cache.\n",
      "2020-06-08 11:28:23.701 | INFO     | covid_model_deaths.deaths_io.checkpoint:load:30 - Loading location from in memory cache.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bedf2b8a6a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mmodel_run_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_run_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "for day in date_list:\n",
    "    VALIDATION_DATE = day # Date to use data upto and including\n",
    "\n",
    "    RUN_TYPE = 'validation'\n",
    "    MODEL_INPUTS_VERSION = 'production-runs/' + DATA_DATE\n",
    "    SNAPSHOT_VERSION = 'production-runs/' + DATA_DATE\n",
    "    DATESTAMP_LABEL = '2020_05_23_Europe' # Will want to change this.\n",
    "\n",
    "    PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/peak_locs_april20_.csv'\n",
    "    PEAK_DURATION_FILE = None\n",
    "    R0_FILE = None\n",
    "    LOCATION_SET_VERSION = 678\n",
    "    r0_locs = []\n",
    "    # Locations where no pseudo data is used\n",
    "    NO_PSEUDO = [\n",
    "        564, # South Dakota\n",
    "        538, # Iowa\n",
    "        # Mexican subnationals\n",
    "        4644, 4657, 4651, 4663, 4665, 4667, 4669\n",
    "    ]\n",
    "\n",
    "    VALIDATION_FOLDER = re.sub(\"-\", \"_\", VALIDATION_DATE)\n",
    "    CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "    OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATA_DATE}/{VALIDATION_FOLDER}'\n",
    "    if not os.path.exists(f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATA_DATE}'):\n",
    "        os.mkdir(f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATA_DATE}')\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)\n",
    "    inputs = InputsContext(f'/ihme/covid-19/model-inputs/{MODEL_INPUTS_VERSION}')\n",
    "    checkpoint = Checkpoint(OUTPUT_DIR)\n",
    "\n",
    "    smooth_draw_path = f'{OUTPUT_DIR}/smoothed_euro_data.csv'\n",
    "    raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "    average_draw_path = f'{OUTPUT_DIR}/past_avg_smoothed_euro_data.csv'\n",
    "    yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_05_22_Europe/smoothed_euro_data.csv'\n",
    "    before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_05_19_Europe/smoothed_euro_data.csv'\n",
    "    compare_average_path = '/ihme/covid-19/deaths/prod/2020_05_22_Europe/smoothed_euro_data.csv'\n",
    "\n",
    "    print(f'Writing to {OUTPUT_DIR}')\n",
    "    print(CODE_DIR)\n",
    "    print(checkpoint)\n",
    "\n",
    "    metadata = {}\n",
    "    with open(f'/ihme/covid-19/model-inputs/{MODEL_INPUTS_VERSION}/metadata.yaml') as f:\n",
    "        metadata['inputs_version'] = yaml.full_load(f)\n",
    "\n",
    "    metadata['run_type'] = RUN_TYPE\n",
    "    metadata['model_inputs_version'] = MODEL_INPUTS_VERSION\n",
    "    metadata['snapshot_version'] = SNAPSHOT_VERSION\n",
    "    metadata['datestamp_label'] = DATESTAMP_LABEL\n",
    "    metadata['peak_file'] = PEAK_FILE\n",
    "    metadata['location_set_version_id'] = LOCATION_SET_VERSION\n",
    "    metadata['output_dir'] = OUTPUT_DIR\n",
    "    metadata['no_pseudo'] = NO_PSEUDO\n",
    "    metadata['average'] = {\n",
    "        'yesterday': yesterday_draw_path,\n",
    "        'before_yesterday': before_yesterday_draw_path\n",
    "    }\n",
    "    metadata['compare_average'] = compare_average_path\n",
    "\n",
    "    with open(f'{OUTPUT_DIR}/metadata.yaml', 'w') as f:\n",
    "        yaml.dump(metadata, f)\n",
    "\n",
    "    def filter_data(data: pd.DataFrame, kind='full') -> pd.DataFrame:\n",
    "        # manually adjust Iceland spike (0 deaths to 5 deaths to 0 deaths in March...)\n",
    "        iceland = data['Country/Region'] == 'Iceland'\n",
    "        iceland_spike = iceland & (data['Date'] == pd.Timestamp('2020-03-15'))\n",
    "        if kind == 'full':\n",
    "            data.loc[iceland_spike, ['Deaths', 'Death rate']] = 0\n",
    "        elif kind == 'deaths':\n",
    "            data = data.loc[~iceland_spike]\n",
    "            min_iceland_date = data.loc[iceland, 'Date'].min()\n",
    "            data.loc[iceland, 'Days'] = (data.loc[iceland, 'Date'] - min_iceland_date).dt.days\n",
    "\n",
    "        catalonia  = data['location_id'] == 60368\n",
    "        catalonia_spike = catalonia & (data['Date'] >= pd.Timestamp('2020-05-21'))\n",
    "        data = data[~catalonia_spike]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_locations(location_set_version_id):\n",
    "        # get locaton_ids\n",
    "        loc_df = get_location_metadata(location_set_id=111,\n",
    "                                       location_set_version_id=location_set_version_id)\n",
    "\n",
    "        # Drop any locations in the US and keep only most detailed for modeling\n",
    "        most_detailed = loc_df['most_detailed'] == 1\n",
    "        # non_us = ~loc_df['path_to_top_parent'].str.startswith('102,')\n",
    "        keep_columns = ['location_id', 'location_ascii_name', 'parent_id', 'level', 'most_detailed']\n",
    "\n",
    "        euro_df = loc_df.loc[most_detailed, keep_columns]\n",
    "        euro_df = euro_df.rename(columns={'location_ascii_name':'Location'})\n",
    "\n",
    "        # Add parents\n",
    "        loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "        loc_df = loc_df.rename(columns={'location_id':'parent_id',\n",
    "                                        'location_ascii_name':'Country/Region'})\n",
    "        euro_df = euro_df.merge(loc_df)\n",
    "\n",
    "        euro_df = euro_df.loc[:, ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "        return euro_df # don't like the name but probably easier to NOT change it.\n",
    "\n",
    "    loc_df = get_locations(LOCATION_SET_VERSION)\n",
    "    input_full_df = filter_data(inputs.load(MEASURES.full_data))\n",
    "    input_death_df = filter_data(inputs.load(MEASURES.deaths), kind='deaths')\n",
    "\n",
    "    # Subset to just dates for validation run\n",
    "    input_full_df = input_full_df[input_full_df['Date'] <= VALIDATION_DATE]\n",
    "    input_death_df = input_death_df[input_death_df['Date'] <= VALIDATION_DATE]\n",
    "\n",
    "    input_age_pop_df = inputs.load(MEASURES.age_pop)\n",
    "    input_age_death_df = inputs.load(MEASURES.age_death)\n",
    "    smoothed_case_df, smoothed_death_df = runner.get_smoothed(input_full_df)\n",
    "\n",
    "    # save cases for viz\n",
    "    smoothed_case_df[[COLUMNS.location_id, COLUMNS.date, 'ln(case rate)', 'population']].to_csv(\n",
    "        f'{OUTPUT_DIR}/smoothed_cases.csv', index=False\n",
    "    )\n",
    "\n",
    "    # Save pops for Bobby.\n",
    "    pop_df = input_age_pop_df.merge(loc_df).reset_index(drop=True)\n",
    "    pop_df[['location_id', 'Location', 'age_group', 'population']].to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "\n",
    "    checkpoint.write('location', loc_df)\n",
    "    checkpoint.write('full_data', input_full_df)\n",
    "    checkpoint.write('deaths', input_death_df)\n",
    "    checkpoint.write('smoothed_cases', smoothed_case_df)\n",
    "    checkpoint.write('smoothed_deaths', smoothed_death_df)\n",
    "    checkpoint.write('age_pop', input_age_pop_df)\n",
    "    checkpoint.write('age_death', input_age_death_df)\n",
    "\n",
    "    #%%time\n",
    "    full_df = checkpoint.load('full_data')\n",
    "    death_df = checkpoint.load('deaths')\n",
    "    age_pop_df = checkpoint.load('age_pop')\n",
    "    age_death_df = checkpoint.load('age_death')\n",
    "\n",
    "    full_df.to_csv(f'{OUTPUT_DIR}/full_df.csv', index=False)\n",
    "    death_df.to_csv(f'{OUTPUT_DIR}/death_df.csv', index=False)\n",
    "    \n",
    "    backcast_location_ids = runner.get_backcast_location_ids(full_df, most_detailed=False)\n",
    "    cases_and_backcast_deaths_df = runner.make_cases_and_backcast_deaths(full_df, death_df, age_pop_df, \n",
    "                                                                         age_death_df, backcast_location_ids, \n",
    "                                                                         subnat=False)\n",
    "\n",
    "    cases_and_backcast_deaths_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n",
    "    checkpoint.write('cases_and_backcast_deaths', cases_and_backcast_deaths_df)\n",
    "    \n",
    "    #%%time\n",
    "    cases_and_backcast_deaths_df = checkpoint.load('cases_and_backcast_deaths')\n",
    "    loc_df = checkpoint.load('location')\n",
    "\n",
    "    # loc_df needs to be updated with locations that have death data\n",
    "    # must have > 0/NaN deaths , seems to also need case data\n",
    "    #model_run_locs = cases_and_backcast_deaths_df[cases_and_backcast_deaths_df['Deaths'].notnull() & cases_and_backcast_deaths_df['Confirmed case rate'].notnull()]\n",
    "    model_run_locs = cases_and_backcast_deaths_df\n",
    "    model_run_locs.to_csv(f'{OUTPUT_DIR}/model_locations.csv', index=False)\n",
    "    model_run_locs = model_run_locs['location_id'].unique()\n",
    "    \n",
    "    stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cases_and_backcast_deaths_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-935bc29758e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcases_and_backcast_deaths_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_run_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cases_and_backcast_deaths_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = cases_and_backcast_deaths_df\n",
    "df = df[df['location_id'] > 0]\n",
    "t = df.groupby(df['location_id']).mean().dropna()\n",
    "model_run_locs = t.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Confirmed case rate</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Death rate</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>80</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>80</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>80</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>80</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>80</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>613.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location_id Province/State Country/Region       Date  Confirmed  \\\n",
       "3276           80         France         France 2020-03-01      191.0   \n",
       "3277           80         France         France 2020-03-02      212.0   \n",
       "3278           80         France         France 2020-03-03      285.0   \n",
       "3279           80         France         France 2020-03-04      423.0   \n",
       "3280           80         France         France 2020-03-05      613.0   \n",
       "\n",
       "      Confirmed case rate  Deaths  Death rate  population  \n",
       "3276             0.000003     NaN         NaN         NaN  \n",
       "3277             0.000003     NaN         NaN         NaN  \n",
       "3278             0.000004     NaN         NaN         NaN  \n",
       "3279             0.000006     NaN         NaN         NaN  \n",
       "3280             0.000009     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_run_locs = cases_and_backcast_deaths_df[cases_and_backcast_deaths_df['Deaths'].notnull() & cases_and_backcast_deaths_df['Confirmed case rate'].notnull()]\n",
    "cases_and_backcast_deaths_df[cases_and_backcast_deaths_df['location_id'] == 80].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
